<!DOCTYPE html>
<html>
<head>
  <title>Hand Tracking + Visible Floating Buttons</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: #111;
    }
    #webcam {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      transform: scaleX(-1);
      z-index: 1;
    }
    #canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 2;
      pointer-events: none;
    }
  </style>
</head>
<body>

<video id="webcam" autoplay playsinline muted></video>
<canvas id="canvas"></canvas>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose"></script>

<script>
  const video = document.getElementById('webcam');
  const canvas = document.getElementById('canvas');
  const ctx = canvas.getContext('2d');
  let model;

  // Define buttons with screen % positions
  const buttons = [
    { x: 0.25, y: 0.3, r: 60, color: 'blue', hover: false },
    { x: 0.5, y: 0.5, r: 70, color: 'green', hover: false },
    { x: 0.75, y: 0.3, r: 60, color: 'orange', hover: false },
  ];

  function resizeCanvas() {
    canvas.width = window.innerWidth;
    canvas.height = window.innerHeight;
  }

  window.addEventListener('resize', resizeCanvas);
  resizeCanvas();

  async function setupCamera() {
    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
    video.srcObject = stream;
    return new Promise(resolve => {
      video.onloadedmetadata = () => resolve(video);
    });
  }

  function isInsideButton(px, py, button) {
    const dx = px - button.x;
    const dy = py - button.y;
    return Math.sqrt(dx * dx + dy * dy) < button.r;
  }

  async function main() {
    await setupCamera();
    model = await handpose.load();
    detectHands();
  }

  async function detectHands() {
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    // Convert button x/y % into px
    const renderedButtons = buttons.map(b => ({
      ...b,
      x: b.x * canvas.width,
      y: b.y * canvas.height
    }));

    // Draw buttons
    renderedButtons.forEach(button => {
      ctx.beginPath();
      ctx.arc(button.x, button.y, button.r, 0, 2 * Math.PI);
      ctx.fillStyle = button.hover ? 'red' : button.color;
      ctx.fill();
    });

    renderedButtons.forEach(b => b.hover = false);

    const predictions = await model.estimateHands(video);
    if (predictions.length > 0) {
      for (let hand of predictions) {
        for (let point of hand.landmarks) {
          const x = point[0] / video.videoWidth * canvas.width;
          const y = point[1] / video.videoHeight * canvas.height;

          ctx.beginPath();
          ctx.arc(x, y, 8, 0, 2 * Math.PI);
          ctx.fillStyle = 'red';
          ctx.fill();

          renderedButtons.forEach(button => {
            if (isInsideButton(x, y, button)) {
              button.hover = true;
            }
          });
        }
      }
    }

    requestAnimationFrame(detectHands);
  }

  main();
</script>

</body>
</html>
